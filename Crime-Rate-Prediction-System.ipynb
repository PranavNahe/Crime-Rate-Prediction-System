{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOhcv4M_sS3P",
        "outputId": "c8206ec7-5e7c-418d-fa69-cf8f3263ca70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsUjQh16tBB3",
        "outputId": "6577e9cb-ba65-4b75-ed82-e112191c7eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Dataset\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/My Drive/Dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr975AD4sV9_",
        "outputId": "678ffc87-6809-4dd9-f6af-0fd020efaada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6465835182492922\n",
            "[[30250  2664    64   835  1351]\n",
            " [ 6304  6497    76    81   439]\n",
            " [ 1470   418    37    62   210]\n",
            " [ 3499   376    15  2176   407]\n",
            " [ 3790   727    24   282  3291]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Assault       0.67      0.86      0.75     35164\n",
            "Break and Enter       0.61      0.48      0.54     13397\n",
            "     Theft Over       0.17      0.02      0.03      2197\n",
            "        Robbery       0.63      0.34      0.44      6473\n",
            "     Auto Theft       0.58      0.41      0.48      8114\n",
            "\n",
            "       accuracy                           0.65     65345\n",
            "      macro avg       0.53      0.42      0.45     65345\n",
            "   weighted avg       0.62      0.65      0.62     65345\n",
            "\n",
            "0.6585660723850333\n",
            "[[31196  2193    31   602  1142]\n",
            " [ 6450  6460    67    57   363]\n",
            " [ 1545   418    24    32   178]\n",
            " [ 3666   341     9  2074   383]\n",
            " [ 3891   765    14   164  3280]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Assault       0.67      0.89      0.76     35164\n",
            "Break and Enter       0.63      0.48      0.55     13397\n",
            "     Theft Over       0.17      0.01      0.02      2197\n",
            "        Robbery       0.71      0.32      0.44      6473\n",
            "     Auto Theft       0.61      0.40      0.49      8114\n",
            "\n",
            "       accuracy                           0.66     65345\n",
            "      macro avg       0.56      0.42      0.45     65345\n",
            "   weighted avg       0.64      0.66      0.63     65345\n",
            "\n",
            "0.6422679623536613\n",
            "[[30360  2544    84   860  1316]\n",
            " [ 6556  6223    82    86   450]\n",
            " [ 1512   412    36    45   192]\n",
            " [ 3484   363    19  2229   378]\n",
            " [ 3990   709    33   261  3121]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Assault       0.66      0.86      0.75     35164\n",
            "Break and Enter       0.61      0.46      0.53     13397\n",
            "     Theft Over       0.14      0.02      0.03      2197\n",
            "        Robbery       0.64      0.34      0.45      6473\n",
            "     Auto Theft       0.57      0.38      0.46      8114\n",
            "\n",
            "       accuracy                           0.64     65345\n",
            "      macro avg       0.52      0.41      0.44     65345\n",
            "   weighted avg       0.62      0.64      0.61     65345\n",
            "\n",
            "0.548672430943454\n",
            "[[35017    53     3     0    91]\n",
            " [12986   411     0     0     0]\n",
            " [ 2161     3     0     0    33]\n",
            " [ 6345    46     0     0    82]\n",
            " [ 7677    12     0     0   425]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Assault       0.55      1.00      0.70     35164\n",
            "Break and Enter       0.78      0.03      0.06     13397\n",
            "     Theft Over       0.00      0.00      0.00      2197\n",
            "        Robbery       0.00      0.00      0.00      6473\n",
            "     Auto Theft       0.67      0.05      0.10      8114\n",
            "\n",
            "       accuracy                           0.55     65345\n",
            "      macro avg       0.40      0.22      0.17     65345\n",
            "   weighted avg       0.54      0.55      0.40     65345\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------------------------#\n",
        "\n",
        "#1) IMPORT LIBRARIES\n",
        "\n",
        "#Computation and Structuring:\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#Modeling:\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "#Testing:\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "#--------------------------------------------------#\n",
        "\n",
        "#2) DATA IMPORT AND PRE-PROCESSING\n",
        "\n",
        "#import full data set\n",
        "df = pd.read_csv('Major_Crime_Indicators.csv',sep=',') \n",
        "\n",
        "#list of relevant columns for model\n",
        "col_list = ['occurrenceyear',\t'occurrencemonth','occurrenceday','occurrencedayofyear','occurrencedayofweek','occurrencehour','MCI',\t'Division',\t'Hood_ID','premisetype']\n",
        "\n",
        "#dataframe created from list of relevant columns\n",
        "\n",
        "df2 = df[col_list]\n",
        "df2 = df2[df2['occurrenceyear'] > 2013] #drop the values..... data set is filtered based on reported date, we're ignoring these old crimes.\n",
        "\n",
        "#Factorize dependent variable column:\n",
        "\n",
        "crime_var = pd.factorize(df2['MCI']) #codes the list of crimes to a int64 variable\n",
        "df2['MCI'] = crime_var[0]\n",
        "definition_list_MCI = crime_var[1] #create an index reference so we know which crimes are coded to which factors\n",
        "\n",
        "#factorize independent variables:\n",
        "\n",
        "#factorize premisetype:\n",
        "\n",
        "premise_var = pd.factorize(df2['premisetype'])\n",
        "df2['premisetype'] = premise_var[0]\n",
        "definition_list_premise = premise_var[1] \n",
        "\n",
        "#factorize occurenceyear:\n",
        "\n",
        "year_var = pd.factorize(df2['occurrenceyear'])\n",
        "df2['occurrenceyear'] = year_var[0]\n",
        "definition_list_year = year_var[1] \n",
        "\n",
        "#factorize occurencemonth:\n",
        "\n",
        "month_var = pd.factorize(df2['occurrencemonth'])\n",
        "df2['occurrencemonth'] = month_var[0]\n",
        "definition_list_month = month_var[1] \n",
        "\n",
        "#factorize occurenceday:\n",
        "\n",
        "day_var = pd.factorize(df2['occurrenceday'])\n",
        "df2['occurenceday'] = day_var[0]\n",
        "definition_list_day = day_var[1] \n",
        "\n",
        "#factorize occurencedayofweek:\n",
        "\n",
        "dayweek_var = pd.factorize(df2['occurrencedayofweek'])\n",
        "df2['occurrencedayofweek'] = dayweek_var[0]\n",
        "definition_list_day = dayweek_var[1] \n",
        "\n",
        "#factorize division:\n",
        "\n",
        "division_var = pd.factorize(df2['Division'])\n",
        "df2['Division'] = division_var[0]\n",
        "definition_list_division = division_var[1] \n",
        "\n",
        "#factorize HOOD_ID:\n",
        "\n",
        "hood_var = pd.factorize(df2['Hood_ID'])\n",
        "df2['Hood_ID'] = hood_var[0]\n",
        "definition_list_hood = hood_var[1] \n",
        "\n",
        "#factorize occurencehour:\n",
        "\n",
        "hour_var = pd.factorize(df2['occurrencehour'])\n",
        "df2['occurrencehour'] = hour_var[0]\n",
        "definition_list_hour = hour_var[1] \n",
        "\n",
        "#factorize occurencedayofyear:\n",
        "\n",
        "dayyear_var = pd.factorize(df2['occurrencedayofyear'])\n",
        "df2['occurrencedayofyear'] = dayyear_var[0]\n",
        "definition_list_dayyear = dayyear_var[1] \n",
        "\n",
        "#set X and Y:\n",
        "\n",
        "X = df2.drop(['MCI'],axis=1).values #sets x and converts to an array\n",
        "\n",
        "y = df2['MCI'].values #sets y and converts to an array\n",
        "\n",
        "#split the data into train and test sets for numeric encoded dataset:\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)\n",
        "\n",
        "#need to OneHotEncode all the X variables for input into the classification model:\n",
        "\n",
        "binary_encoder = OneHotEncoder(sparse=False)\n",
        "encoded_X = binary_encoder.fit_transform(X)\n",
        "\n",
        "X_train_OH, X_test_OH, y_train_OH, y_test_OH = train_test_split(encoded_X, y, test_size = 0.25, random_state = 21)\n",
        "\n",
        "\n",
        "#--------------------------------------------------#\n",
        "\n",
        "#3) MODELING AND TESTING:\n",
        "\n",
        "#Numeric Encoded Model w/ SKLEARN:\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test) # Predicting the Test set results\n",
        "#n_estmators are the number of trees you wish to build before getting to the final precsion\n",
        "#criterion is used to measure the quality of split. Entropy here measures the uncertainty in the group o fthe observations.\n",
        "#random_state is used to make sure the results can make a pattern or the splits whcih we are generating are reproductive.\n",
        "\n",
        "print(accuracy_score(y_test, y_pred)) #accuracy at 0.63\n",
        "print(confusion_matrix(y_test, y_pred)) \n",
        "print(classification_report(y_test,y_pred, target_names=definition_list_MCI)) \n",
        "\n",
        "#theft over is pulling down results. Pretty good on Assault (largest sample size) and break and enter \n",
        "\n",
        "\n",
        "#One Hot Encoded Model w/ SKLEARN:\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
        "classifier.fit(X_train_OH, y_train_OH)\n",
        "y_pred_OH = classifier.predict(X_test_OH) # Predicting the Test set results\n",
        "\n",
        "print(accuracy_score(y_test_OH, y_pred_OH)) #modest improvement to 0.648\n",
        "print(confusion_matrix(y_test_OH, y_pred_OH)) \n",
        "print(classification_report(y_test_OH,y_pred_OH, target_names=definition_list_MCI)) #modest improvement\n",
        "\n",
        "#Balanced Class Weight doesn't make a big difference for results:\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42, class_weight='balanced')\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test) \n",
        "print(accuracy_score(y_test, y_pred)) #accuracy at 0.63\n",
        "print(confusion_matrix(y_test, y_pred)) \n",
        "print(classification_report(y_test,y_pred, target_names=definition_list_MCI)) \n",
        "\n",
        "#--------------------------------------------------#\n",
        "\n",
        "#gradientboost performs poorly relative to randomforest\n",
        "\n",
        "grad_class = GradientBoostingClassifier(learning_rate=0.1,n_estimators = 10, random_state = 42)\n",
        "grad_class.fit(X_train_OH, y_train_OH)\n",
        "y_pred_OH = grad_class.predict(X_test_OH) # Predicting the Test set results\n",
        "\n",
        "print(accuracy_score(y_test_OH, y_pred_OH)) #modest improvement to 0.648\n",
        "print(confusion_matrix(y_test_OH, y_pred_OH)) \n",
        "print(classification_report(y_test_OH,y_pred_OH, target_names=definition_list_MCI)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb1SzEa4ttD_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}